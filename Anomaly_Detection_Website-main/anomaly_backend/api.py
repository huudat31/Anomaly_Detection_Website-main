"""
Anomaly Detection API Server
Enhanced version with better structure, error handling, and security
"""

from flask import Flask, jsonify, request, send_file
from flask_cors import CORS
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address
import pandas as pd
import os
import json
import uuid
from datetime import datetime, timedelta, date
import threading
import logging
from pathlib import Path
from functools import wraps
import signal
import sys
from typing import Dict, Any, Optional, Tuple
import traceback

# Import tá»« main.py Ä‘Ã£ refactor
try:
    from main import AnomalyDetectionSystem, AnomalyDetectionConfig
except ImportError as e:
    print(f"âŒ KhÃ´ng thá»ƒ import tá»« main.py: {e}")
    sys.exit(1)

# =============================================================================
# APP CONFIGURATION
# =============================================================================

app = Flask(__name__)
CORS(app, resources={
    r"/api/*": {
        "origins": ["*"],
        "methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
        "allow_headers": ["Content-Type", "Authorization"]
    }
})

# Rate limiting
# Rate limiting - Correct initialization for Flask-Limiter 3.x
limiter = Limiter(
    app=app,
    key_func=get_remote_address,
    default_limits=["100 per hour", "20 per minute"]
)

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

def setup_logging():
    """Cáº¥u hÃ¬nh logging chi tiáº¿t"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('api_server.log', encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    # Táº¯t debug logs tá»« werkzeug trong production
    if not app.debug:
        logging.getLogger('werkzeug').setLevel(logging.WARNING)

setup_logging()
logger = logging.getLogger(__name__)

# =============================================================================
# GLOBAL STATE MANAGEMENT
# =============================================================================

class ProcessingState:
    """Quáº£n lÃ½ tráº¡ng thÃ¡i xá»­ lÃ½ thread-safe"""
    
    def __init__(self):
        self._lock = threading.Lock()
        self._state = {
            "is_running": False,
            "progress": 0,
            "message": "Sáºµn sÃ ng",
            "last_run": None,
            "anomalies_count": 0,
            "total_samples": 0,
            "success": None,
            "error": None,
            "run_id": None,
            "start_time": None,
            "estimated_finish": None
        }
    
    def update(self, **kwargs):
        """Cáº­p nháº­t tráº¡ng thÃ¡i thread-safe"""
        with self._lock:
            self._state.update(kwargs)
    
    def get_state(self) -> Dict[str, Any]:
        """Láº¥y tráº¡ng thÃ¡i hiá»‡n táº¡i"""
        with self._lock:
            return self._state.copy()
    
    def reset(self):
        """Reset tráº¡ng thÃ¡i vá» ban Ä‘áº§u"""
        with self._lock:
            self._state.update({
                "is_running": False,
                "progress": 0,
                "message": "Sáºµn sÃ ng",
                "success": None,
                "error": None,
                "run_id": None,
                "start_time": None,
                "estimated_finish": None
            })

processing_state = ProcessingState()

class ProgressCallback:
    """Callback Ä‘á»ƒ cáº­p nháº­t tiáº¿n trÃ¬nh vá»›i Æ°á»›c tÃ­nh thá»i gian"""
    
    def __init__(self, run_id: str):
        self.run_id = run_id
        self.start_time = datetime.now()
        self.last_update = self.start_time
    
    def update(self, progress: int, message: str):
        """Cáº­p nháº­t tiáº¿n trÃ¬nh vá»›i Æ°á»›c tÃ­nh thá»i gian hoÃ n thÃ nh"""
        current_time = datetime.now()
        
        # Æ¯á»›c tÃ­nh thá»i gian hoÃ n thÃ nh
        if progress > 0:
            elapsed = (current_time - self.start_time).total_seconds()
            estimated_total = elapsed * 100 / progress
            estimated_finish = self.start_time + timedelta(seconds=estimated_total)
        else:
            estimated_finish = None
        
        processing_state.update(
            progress=progress,
            message=message,
            estimated_finish=estimated_finish.isoformat() if estimated_finish else None
        )
        
        logger.info(f"[{self.run_id}] Progress: {progress}% - {message}")
        self.last_update = current_time

# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================

def validate_json_request(required_fields: Optional[list] = None) -> dict:
    """Validate JSON request vÃ  tráº£ vá» data"""
    if not request.is_json:
        raise ValueError("Content-Type pháº£i lÃ  application/json")
    
    data = request.get_json()
    if not isinstance(data, dict):
        raise ValueError("Request body pháº£i lÃ  JSON object")
    
    if required_fields:
        missing_fields = [field for field in required_fields if field not in data]
        if missing_fields:
            raise ValueError(f"Thiáº¿u cÃ¡c trÆ°á»ng báº¯t buá»™c: {missing_fields}")
    
    return data

def handle_api_error(func):
    """Decorator Ä‘á»ƒ xá»­ lÃ½ lá»—i API má»™t cÃ¡ch thá»‘ng nháº¥t"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except ValueError as e:
            logger.warning(f"Validation error in {func.__name__}: {e}")
            return jsonify({
                "success": False,
                "error": "VALIDATION_ERROR",
                "message": str(e)
            }), 400
        except FileNotFoundError as e:
            logger.error(f"File not found in {func.__name__}: {e}")
            return jsonify({
                "success": False,
                "error": "FILE_NOT_FOUND",
                "message": f"KhÃ´ng tÃ¬m tháº¥y file: {str(e)}"
            }), 404
        except Exception as e:
            logger.error(f"Unexpected error in {func.__name__}: {e}")
            logger.error(traceback.format_exc())
            return jsonify({
                "success": False,
                "error": "INTERNAL_ERROR",
                "message": "ÄÃ£ xáº£y ra lá»—i ná»™i bá»™"
            }), 500
    return wrapper

def ensure_directories():
    """Táº¡o cÃ¡c thÆ° má»¥c cáº§n thiáº¿t"""
    directories = ['data', 'models', 'outputs', 'logs']
    for directory in directories:
        Path(directory).mkdir(exist_ok=True)
        logger.info(f"ÄÃ£ táº¡o/kiá»ƒm tra thÆ° má»¥c: {directory}")

# =============================================================================
# CORE PROCESSING FUNCTIONS
# =============================================================================

def run_anomaly_detection_with_callback():
    """
    Cháº¡y anomaly detection vá»›i callback Ä‘á»ƒ cáº­p nháº­t tráº¡ng thÃ¡i
    PhiÃªn báº£n cáº£i tiáº¿n vá»›i xá»­ lÃ½ lá»—i tá»‘t hÆ¡n
    """
    run_id = str(uuid.uuid4())[:8]
    
    try:
        # Khá»Ÿi táº¡o tráº¡ng thÃ¡i
        processing_state.update(
            is_running=True,
            progress=0,
            message="Äang khá»Ÿi táº¡o há»‡ thá»‘ng...",
            success=None,
            error=None,
            run_id=run_id,
            start_time=datetime.now().isoformat()
        )
        
        logger.info(f"[{run_id}] Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh phÃ¡t hiá»‡n anomaly")
        
        # Khá»Ÿi táº¡o há»‡ thá»‘ng
        config = AnomalyDetectionConfig()
        system = AnomalyDetectionSystem(config)
        callback = ProgressCallback(run_id)
        
        # Pipeline xá»­ lÃ½ vá»›i cÃ¡c checkpoint
        steps = [
            (10, "Äang sinh dá»¯ liá»‡u ngáº«u nhiÃªn...", system.generate_data),
            (30, "Äang táº£i vÃ  trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng...", system.load_and_extract_features),
            (50, "Äang huáº¥n luyá»‡n Autoencoder...", None),  # Special handling
            (70, "Äang phÃ¡t hiá»‡n báº¥t thÆ°á»ng...", None),    # Special handling
            (85, "Äang xá»­ lÃ½ cáº£nh bÃ¡o...", None),          # Special handling
            (95, "Äang xuáº¥t káº¿t quáº£...", None)             # Special handling
        ]
        
        # BÆ°á»›c 1-2: Sinh dá»¯ liá»‡u vÃ  trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng
        features = None
        for progress, message, func in steps[:2]:
            callback.update(progress, message)
            
            if func == system.generate_data:
                if not func():
                    raise Exception("KhÃ´ng thá»ƒ sinh dá»¯ liá»‡u")
            elif func == system.load_and_extract_features:
                features = func()
                if features is None:
                    raise Exception("KhÃ´ng thá»ƒ táº£i vÃ  trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng")
        
        # BÆ°á»›c 3: Huáº¥n luyá»‡n mÃ´ hÃ¬nh
        callback.update(50, "Äang huáº¥n luyá»‡n Autoencoder...")
        if not system.train_model(features):
            raise Exception("KhÃ´ng thá»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh")
        
        # BÆ°á»›c 4: PhÃ¡t hiá»‡n anomaly
        callback.update(70, "Äang phÃ¡t hiá»‡n báº¥t thÆ°á»ng...")
        detection_result = system.detect_anomalies_in_data(features)
        if detection_result is None:
            raise Exception("KhÃ´ng thá»ƒ phÃ¡t hiá»‡n anomaly")
        
        anomalies, losses = detection_result
        anomalies_count = sum(anomalies)
        total_samples = len(anomalies)
        
        # BÆ°á»›c 5: Xá»­ lÃ½ cáº£nh bÃ¡o
        callback.update(85, "Äang xá»­ lÃ½ cáº£nh bÃ¡o...")
        system.handle_alerts(anomalies, features)
        
        # BÆ°á»›c 6: Xuáº¥t káº¿t quáº£
        callback.update(95, "Äang xuáº¥t káº¿t quáº£...")
        system.export_detection_results(anomalies, losses)
        
        # LÆ°u lá»‹ch sá»­
        system.save_run_history(True, anomalies_count, total_samples)
        
        # HoÃ n thÃ nh
        callback.update(100, "HoÃ n thÃ nh thÃ nh cÃ´ng")
        
        processing_state.update(
            is_running=False,
            last_run=datetime.now().isoformat(),
            anomalies_count=anomalies_count,
            total_samples=total_samples,
            success=True,
            error=None
        )
        
        logger.info(f"[{run_id}] HoÃ n thÃ nh: {anomalies_count}/{total_samples} anomalies")
        
    except Exception as e:
        error_msg = str(e)
        logger.error(f"[{run_id}] Lá»—i trong quÃ¡ trÃ¬nh xá»­ lÃ½: {error_msg}")
        logger.error(f"[{run_id}] Stack trace: {traceback.format_exc()}")
        
        processing_state.update(
            is_running=False,
            progress=0,
            message=f"Lá»—i: {error_msg}",
            last_run=datetime.now().isoformat(),
            success=False,
            error=error_msg
        )

# =============================================================================
# API ENDPOINTS
# =============================================================================

@app.route('/api/health', methods=['GET'])
@handle_api_error
def health_check():
    """Health check endpoint vá»›i kiá»ƒm tra chi tiáº¿t"""
    config = AnomalyDetectionConfig()
    
    checks = {
        "api_status": "healthy",
        "config_loaded": True,
        "data_directory": Path(config.get("data_path")).parent.exists(),
        "models_directory": Path(config.get("model_path")).parent.exists(),
        "processing_available": not processing_state.get_state()["is_running"],
        "disk_space": _check_disk_space(),
        "memory_available": _check_memory()
    }
    
    all_healthy = all(checks.values())
    
    return jsonify({
        "status": "healthy" if all_healthy else "degraded",
        "timestamp": datetime.now().isoformat(),
        "version": "2.0.0",
        "checks": checks,
        "uptime": _get_uptime()
    }), 200 if all_healthy else 503

@app.route('/api/status', methods=['GET'])
@handle_api_error
def get_status():
    """Láº¥y tráº¡ng thÃ¡i hiá»‡n táº¡i vá»›i thÃ´ng tin chi tiáº¿t"""
    state = processing_state.get_state()
    
    # ThÃªm thÃ´ng tin runtime
    if state["start_time"]:
        start_time = datetime.fromisoformat(state["start_time"])
        runtime = (datetime.now() - start_time).total_seconds()
        state["runtime_seconds"] = round(runtime, 2)
    
    return jsonify({
        "success": True,
        "data": state,
        "timestamp": datetime.now().isoformat()
    })

@app.route('/api/start', methods=['POST'])
@limiter.limit("5 per minute")
@handle_api_error
def start_detection():
    """Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh phÃ¡t hiá»‡n anomaly vá»›i validation"""
    current_state = processing_state.get_state()
    
    if current_state["is_running"]:
        return jsonify({
            "success": False,
            "error": "ALREADY_RUNNING",
            "message": "QuÃ¡ trÃ¬nh Ä‘ang cháº¡y, vui lÃ²ng Ä‘á»£i",
            "current_progress": current_state["progress"]
        }), 409
    
    # Kiá»ƒm tra tÃ i nguyÃªn há»‡ thá»‘ng
    if not _check_system_resources():
        return jsonify({
            "success": False,
            "error": "INSUFFICIENT_RESOURCES",
            "message": "TÃ i nguyÃªn há»‡ thá»‘ng khÃ´ng Ä‘á»§ Ä‘á»ƒ cháº¡y"
        }, 503)
    
    # Cháº¡y trong background thread
    thread = threading.Thread(
        target=run_anomaly_detection_with_callback,
        name=f"AnomalyDetection-{datetime.now().strftime('%Y%m%d-%H%M%S')}"
    )
    thread.daemon = True
    thread.start()
    
    return jsonify({
        "success": True,
        "message": "ÄÃ£ báº¯t Ä‘áº§u quÃ¡ trÃ¬nh phÃ¡t hiá»‡n anomaly",
        "run_id": processing_state.get_state()["run_id"]
    })

@app.route('/api/stop', methods=['POST'])
@handle_api_error
def stop_processing():
    """Dá»«ng quÃ¡ trÃ¬nh xá»­ lÃ½"""
    current_state = processing_state.get_state()
    
    if not current_state["is_running"]:
        return jsonify({
            "success": False,
            "error": "NOT_RUNNING",
            "message": "KhÃ´ng cÃ³ quÃ¡ trÃ¬nh nÃ o Ä‘ang cháº¡y"
        }), 400
    
    # Cáº­p nháº­t tráº¡ng thÃ¡i yÃªu cáº§u dá»«ng
    processing_state.update(
        message="Äang yÃªu cáº§u dá»«ng...",
        progress=current_state.get("progress", 0)
    )
    
    return jsonify({
        "success": True,
        "message": "ÄÃ£ gá»­i yÃªu cáº§u dá»«ng quÃ¡ trÃ¬nh"
    })

@app.route('/api/results', methods=['GET'])
@handle_api_error
def get_results():
    """Láº¥y káº¿t quáº£ phÃ¡t hiá»‡n anomaly vá»›i Ä‘á»‹nh dáº¡ng chuáº©n cho frontend"""
    anomalies = []
    total_records = 0
    anomalies_count = 0
    # Äá»c dá»¯ liá»‡u traffic
    data_path = Path('data/traffic.csv')
    if data_path.exists():
        df = pd.read_csv(data_path)
        total_records = len(df)
        # Äá»c káº¿t quáº£ anomaly (true/false) vÃ  confidence
        result_path = Path('result.json')
        anomaly_flags = []
        confidences = []
        if result_path.exists():
            with open(result_path, 'r') as f:
                result_json = json.load(f)
                if isinstance(result_json, dict):
                    anomaly_flags = result_json.get('anomalies')
                    # Láº¥y confidence: láº¥y máº£ng cuá»‘i cÃ¹ng trong dict cÃ³ cÃ¹ng chiá»u anomalies vÃ  lÃ  list sá»‘
                    confidences = []
                    candidate_keys = [k for k, v in result_json.items() if isinstance(v, list) and len(v) == len(anomaly_flags) and all(isinstance(x, (float, int)) for x in v)]
                    if candidate_keys:
                        confidences = result_json[candidate_keys[-1]]
        for idx, row in df.iterrows():
            # Chuáº©n hÃ³a timestamp
            raw_time = row['timestamp'] if 'timestamp' in row else ''
            try:
                # Náº¿u chá»‰ cÃ³ HH:mm:ss thÃ¬ ghÃ©p ngÃ y hÃ´m nay
                if len(str(raw_time)) == 8 and ':' in str(raw_time):
                    today = date.today().isoformat()
                    timestamp = f"{today}T{raw_time}"
                else:
                    timestamp = str(raw_time)
            except Exception:
                timestamp = str(raw_time)
            is_anomaly = bool(anomaly_flags[idx]) if anomaly_flags and idx < len(anomaly_flags) else False
            if is_anomaly:
                anomalies_count += 1
            confidence = confidences[idx] if confidences and idx < len(confidences) else 0.0
            # Äáº£m báº£o confidence náº±m trong [0, 1] Ä‘á»ƒ frontend hiá»ƒn thá»‹ Ä‘Ãºng %
            if confidence > 1.0:
                confidence = min(confidence / 10.0, 1.0) if confidence <= 10 else min(confidence / 100.0, 1.0)
            elif confidence < 0.0:
                confidence = 0.0
            anomalies.append({
                'id': idx + 1,
                'timestamp': timestamp,
                'value': float(row['duration']) if 'duration' in row else 0,
                'isAnomaly': is_anomaly,
                'confidence': confidence
            })
    return jsonify({
        'success': True,
        'data': {
            'anomalies': {'count': len(anomalies), 'data': anomalies},
            'totalRecords': total_records,
            'anomaliesCount': anomalies_count
        }
    })

@app.route('/api/download/<file_type>', methods=['GET'])
@limiter.limit("10 per minute")
@handle_api_error
def download_file(file_type):
    """Download file káº¿t quáº£ vá»›i validation"""
    config = AnomalyDetectionConfig()
    
    file_mappings = {
        "traffic": config.get("data_path"),
        "alert": config.get("alert_file", "alert.csv"),
        "history": "history.json",
        "config": "config.json",
        "logs": "api_server.log"
    }
    
    if file_type not in file_mappings:
        return jsonify({
            "success": False,
            "error": "INVALID_FILE_TYPE",
            "message": f"File type khÃ´ng há»£p lá»‡. CÃ¡c loáº¡i file cÃ³ sáºµn: {list(file_mappings.keys())}"
        }), 400
    
    file_path = Path(file_mappings[file_type])
    
    if not file_path.exists():
        raise FileNotFoundError(f"File {file_path} khÃ´ng tá»“n táº¡i")
    
    # Kiá»ƒm tra kÃ­ch thÆ°á»›c file
    file_size = file_path.stat().st_size
    if file_size > 100 * 1024 * 1024:  # 100MB
        return jsonify({
            "success": False,
            "error": "FILE_TOO_LARGE",
            "message": f"File quÃ¡ lá»›n ({file_size / 1024 / 1024:.1f}MB). Giá»›i háº¡n 100MB"
        }), 413
    
    return send_file(
        file_path,
        as_attachment=True,
        download_name=f"{file_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{file_path.suffix.lstrip('.')}"
    )

@app.route('/api/config', methods=['GET', 'POST'])
@handle_api_error
def config_endpoint():
    """Láº¥y hoáº·c cáº­p nháº­t cáº¥u hÃ¬nh vá»›i validation"""
    config = AnomalyDetectionConfig()
    
    if request.method == 'GET':
        return jsonify({
            "success": True,
            "data": config.config,
            "timestamp": datetime.now().isoformat()
        })
    
    elif request.method == 'POST':
        # Kiá»ƒm tra xem cÃ³ process Ä‘ang cháº¡y khÃ´ng
        if processing_state.get_state()["is_running"]:
            return jsonify({
                "success": False,
                "error": "PROCESS_RUNNING",
                "message": "KhÃ´ng thá»ƒ thay Ä‘á»•i cáº¥u hÃ¬nh khi Ä‘ang xá»­ lÃ½"
            }), 409
        
        updates = validate_json_request()
        
        # Validate cÃ¡c trÆ°á»ng cáº¥u hÃ¬nh
        _validate_config_updates(updates)
        
        # Backup cáº¥u hÃ¬nh cÅ©
        _backup_config(config.config)
        
        # Cáº­p nháº­t cáº¥u hÃ¬nh
        config.update(updates)
        
        logger.info(f"Cáº¥u hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t: {list(updates.keys())}")
        
        return jsonify({
            "success": True,
            "message": "Cáº¥u hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t",
            "data": config.config,
            "updated_fields": list(updates.keys())
        })

@app.route('/api/history', methods=['GET'])
@handle_api_error
def get_history():
    """Láº¥y lá»‹ch sá»­ cháº¡y vá»›i pagination vÃ  filtering"""
    history_file = Path("history.json")
    
    if not history_file.exists():
        return jsonify({
            "success": True,
            "data": {
                "history": [],
                "pagination": {
                    "page": 1,
                    "per_page": 20,
                    "total": 0,
                    "has_next": False,
                    "has_prev": False
                }
            }
        })
    
    with open(history_file, 'r', encoding='utf-8') as f:
        history = json.load(f)
    
    # Filtering
    success_filter = request.args.get('success')
    if success_filter is not None:
        success_bool = success_filter.lower() in ['true', '1', 'yes']
        history = [h for h in history if h.get('success') == success_bool]
    
    # Sorting
    sort_by = request.args.get('sort_by', 'timestamp')
    reverse = request.args.get('order', 'desc').lower() == 'desc'
    
    if sort_by in ['timestamp', 'anomalies_count', 'total_samples']:
        history.sort(key=lambda x: x.get(sort_by, 0), reverse=reverse)
    
    # Pagination
    page = request.args.get('page', 1, type=int)
    per_page = min(request.args.get('per_page', 20, type=int), 100)
    
    start = (page - 1) * per_page
    end = start + per_page
    paginated_history = history[start:end]
    
    return jsonify({
        "success": True,
        "data": {
            "history": paginated_history,
            "pagination": {
                "page": page,
                "per_page": per_page,
                "total": len(history),
                "total_pages": (len(history) + per_page - 1) // per_page,
                "has_next": end < len(history),
                "has_prev": page > 1
            },
            "filters": {
                "success": success_filter,
                "sort_by": sort_by,
                "order": request.args.get('order', 'desc')
            }
        }
    })

@app.route('/api/system-info', methods=['GET'])
@handle_api_error
def get_system_info():
    """Láº¥y thÃ´ng tin há»‡ thá»‘ng chi tiáº¿t"""
    try:
        import psutil
        import platform
        
        # ThÃ´ng tin há»‡ thá»‘ng
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('.')
        
        system_info = {
            "platform": {
                "system": platform.system(),
                "version": platform.version(),
                "machine": platform.machine(),
                "processor": platform.processor()
            },
            "python": {
                "version": platform.python_version(),
                "implementation": platform.python_implementation()
            },
            "hardware": {
                "cpu_count": psutil.cpu_count(),
                "cpu_count_logical": psutil.cpu_count(logical=True),
                "cpu_percent": psutil.cpu_percent(interval=1)
            },
            "memory": {
                "total": memory.total,
                "available": memory.available,
                "percent": memory.percent,
                "used": memory.used,
                "free": memory.free
            },
            "disk": {
                "total": disk.total,
                "used": disk.used,
                "free": disk.free,
                "percent": (disk.used / disk.total * 100) if disk.total > 0 else 0
            },
            "process": {
                "pid": os.getpid(),
                "threads": threading.active_count(),
                "memory_info": psutil.Process().memory_info()._asdict()
            }
        }
        
        return jsonify({
            "success": True,
            "data": system_info,
            "timestamp": datetime.now().isoformat()
        })
        
    except ImportError:
        return jsonify({
            "success": False,
            "error": "DEPENDENCY_MISSING",
            "message": "Cáº§n cÃ i Ä‘áº·t psutil Ä‘á»ƒ xem thÃ´ng tin há»‡ thá»‘ng: pip install psutil"
        }), 503

@app.route('/api/statistics', methods=['GET'])
def get_statistics():
    """Endpoint tráº£ vá» thá»‘ng kÃª tá»•ng quan"""
    total_records = 0
    anomalies_count = 0
    # which itself is unlikely to be populated as expected from 'history.json'.
    # We'll keep this default for now, as fixing accuracy sourcing is beyond the NaN issue.
    detection_accuracy = 94.2  # Default placeholder

    try:
        # 1. Try to get data from the latest successful run in history.json
        history_path = Path('history.json')
        if history_path.exists():
            try:
                with open(history_path, 'r', encoding='utf-8') as f:
                    history_data = json.load(f)
                    if isinstance(history_data, list) and history_data:
                        latest_successful_run = next(
                            (run for run in reversed(history_data) if run.get('success')),
                            None
                        )
                        if latest_successful_run:
                            total_records = latest_successful_run.get('total_samples', 0)
                            anomalies_count = latest_successful_run.get('anomalies_count', 0)
                            # If accuracy is stored per run, it could be updated here:
                            # detection_accuracy = latest_successful_run.get('accuracy_metric', detection_accuracy)
            except json.JSONDecodeError:
                logger.warning(f"Could not decode history.json for statistics.")
            except Exception as e_hist:
                logger.warning(f"Error reading history.json for statistics: {e_hist}")

        # 2. If history didn't provide data (or total_records is still 0), try result.json
        if total_records == 0:
            result_path = Path('result.json')
            if result_path.exists():
                try:
                    with open(result_path, 'r', encoding='utf-8') as f:
                        results_json = json.load(f)
                        if isinstance(results_json, dict) and 'anomalies' in results_json:
                            anomaly_flags = results_json.get('anomalies', [])
                            if anomaly_flags:  # Ensure it's not empty
                                total_records = len(anomaly_flags)
                                # Sá»­a: anomalies lÃ  list object, Ä‘áº¿m theo isAnomaly
                                anomalies_count = sum(1 for item in anomaly_flags if (isinstance(item, dict) and item.get('isAnomaly')))
                except Exception as e_res:
                    logger.warning(f"Error reading result.json for statistics: {e_res}")

        # 3. If still no total_records, try to count from traffic.csv (anomalies_count will be 0)
        if total_records == 0:
            config = AnomalyDetectionConfig() # Ensure config is loaded to get data_path
            data_path = Path(config.get("data_path", "data/traffic.csv"))
            if data_path.exists():
                try:
                    df = pd.read_csv(data_path)
                    total_records = len(df)
                    # anomalies_count remains 0 as traffic.csv doesn't have 'is_anomaly' by default
                except Exception as e_csv:
                    logger.warning(f"Could not read {data_path} for statistics: {e_csv}")

        return jsonify({
            'success': True,
            'data': {
                'totalRecords': total_records,
                'anomaliesCount': anomalies_count,
                'detectionAccuracy': detection_accuracy # Frontend uses this for "Accuracy" card
            }
        })
    except Exception as e:
        logger.error(f"Error getting statistics: {str(e)}\n{traceback.format_exc()}")
        return jsonify({
            'success': False,
            'error': f'Failed to get statistics: {str(e)}'
        }), 500

@app.route('/api/automation', methods=['POST'])
def trigger_automation():
    """API Ä‘á»ƒ tá»± Ä‘á»™ng sinh dá»¯ liá»‡u, phÃ¡t hiá»‡n báº¥t thÆ°á»ng vÃ  reload backend"""
    import subprocess
    try:
        result1 = subprocess.run([sys.executable, 'generate_random_traffic.py'], capture_output=True, text=True)
        if result1.returncode != 0:
            return jsonify({'success': False, 'error': result1.stderr or result1.stdout})
        result2 = subprocess.run([sys.executable, 'run_detection.py'], capture_output=True, text=True)
        if result2.returncode != 0:
            return jsonify({'success': False, 'error': result2.stderr or result2.stdout})
        return jsonify({'success': True, 'message': 'ÄÃ£ cáº­p nháº­t dá»¯ liá»‡u vÃ  phÃ¡t hiá»‡n báº¥t thÆ°á»ng má»›i.'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/upload', methods=['POST'])
def upload_file():
    """Nháº­n file upload tá»« frontend, lÆ°u vÃ o data/traffic.csv vÃ  cháº¡y phÃ¡t hiá»‡n báº¥t thÆ°á»ng luÃ´n"""
    if 'file' not in request.files:
        return jsonify({'success': False, 'error': 'No file part in the request'}), 400
    file = request.files['file']
    if file.filename == '':
        return jsonify({'success': False, 'error': 'No selected file'}), 400
    save_path = Path('data/traffic.csv')
    save_path.parent.mkdir(parents=True, exist_ok=True)
    if save_path.exists():
        save_path.unlink()
    file.save(str(save_path))
    # Cáº­p nháº­t config Ä‘á»ƒ pipeline khÃ´ng sinh dá»¯ liá»‡u ngáº«u nhiÃªn vÃ  luÃ´n láº¥y Ä‘Ãºng file vá»«a upload
    import sys, subprocess, json, os
    config_path = os.path.join(os.path.dirname(__file__), 'config.json')
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    config['generate_random_data'] = False
    config['data_path'] = str(save_path)
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    # Cháº¡y phÃ¡t hiá»‡n báº¥t thÆ°á»ng ngay sau khi upload
    run_detection_path = os.path.join(os.path.dirname(__file__), 'run_detection.py')
    result = subprocess.run([sys.executable, run_detection_path], capture_output=True, text=True)
    if result.returncode != 0:
        return jsonify({'success': False, 'error': result.stderr or result.stdout}), 500
    return jsonify({'success': True, 'message': 'File uploaded and anomaly detection completed.'})

# =============================================================================
# HELPER FUNCTIONS
# =============================================================================

def _check_disk_space() -> bool:
    """Kiá»ƒm tra dung lÆ°á»£ng Ä‘Ä©a cÃ²n láº¡i"""
    try:
        import psutil
        disk_usage = psutil.disk_usage('.')
        free_percent = disk_usage.free / disk_usage.total * 100
        return free_percent > 10  # Cáº§n Ã­t nháº¥t 10% dung lÆ°á»£ng trá»‘ng
    except:
        return True  # Náº¿u khÃ´ng kiá»ƒm tra Ä‘Æ°á»£c thÃ¬ cho phÃ©p

def _check_memory() -> bool:
    """Kiá»ƒm tra bá»™ nhá»› cÃ³ sáºµn"""
    try:
        import psutil
        memory = psutil.virtual_memory()
        return memory.percent < 90  # RAM sá»­ dá»¥ng dÆ°á»›i 90%
    except:
        return True

def _check_system_resources() -> bool:
    """Kiá»ƒm tra tÃ i nguyÃªn há»‡ thá»‘ng cÃ³ Ä‘á»§ khÃ´ng"""
    return _check_disk_space() and _check_memory()

def _get_uptime() -> str:
    """Láº¥y thá»i gian hoáº¡t Ä‘á»™ng cá»§a server"""
    # CÃ³ thá»ƒ implement logic Ä‘á»ƒ track uptime
    return "N/A"

def _calculate_anomaly_rate(anomalies: int, total: int) -> float:
    """TÃ­nh tá»· lá»‡ anomaly"""
    if total == 0:
        return 0.0
    return round(anomalies / total * 100, 2)

def _validate_config_updates(updates: dict):
    """Validate cÃ¡c update cáº¥u hÃ¬nh"""
    allowed_fields = {
        'batch_size', 'epochs', 'learning_rate', 'threshold',
        'data_path', 'model_path', 'alert_file'
    }
    
    invalid_fields = set(updates.keys()) - allowed_fields
    if invalid_fields:
        raise ValueError(f"CÃ¡c trÆ°á»ng khÃ´ng há»£p lá»‡: {invalid_fields}")
    
    # Validate specific types
    if 'batch_size' in updates and not isinstance(updates['batch_size'], int):
        raise ValueError("batch_size pháº£i lÃ  sá»‘ nguyÃªn")
    
    if 'epochs' in updates and not isinstance(updates['epochs'], int):
        raise ValueError("epochs pháº£i lÃ  sá»‘ nguyÃªn")

def _backup_config(config: dict):
    """Backup cáº¥u hÃ¬nh cÅ©"""
    backup_file = f"config_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    try:
        with open(backup_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        logger.info(f"ÄÃ£ backup cáº¥u hÃ¬nh vÃ o {backup_file}")
    except Exception as e:
        logger.warning(f"KhÃ´ng thá»ƒ backup cáº¥u hÃ¬nh: {e}")

# =============================================================================
# ERROR HANDLERS
# =============================================================================

@app.errorhandler(404)
def not_found(error):
    return jsonify({
        "success": False,
        "error": "NOT_FOUND",
        "message": "API endpoint khÃ´ng tá»“n táº¡i",
        "available_endpoints": [
            "GET /api/health",
            "GET /api/status", 
            "POST /api/start",
            "POST /api/stop",
            "GET /api/results",
            "GET /api/download/<type>",
            "GET|POST /api/config",
            "GET /api/history",
            "GET /api/system-info"
        ]
    }), 404

@app.errorhandler(405)
def method_not_allowed(error):
    return jsonify({
        "success": False,
        "error": "METHOD_NOT_ALLOWED",
        "message": "PhÆ°Æ¡ng thá»©c HTTP khÃ´ng Ä‘Æ°á»£c há»— trá»£ cho endpoint nÃ y"
    }), 405

@app.errorhandler(413)
def request_entity_too_large(error):
    return jsonify({
        "success": False,
        "error": "REQUEST_TOO_LARGE",
        "message": "Request quÃ¡ lá»›n"
    }), 413

@app.errorhandler(429)
def ratelimit_handler(e):
    return jsonify({
        "success": False,
        "error": "RATE_LIMIT_EXCEEDED",
        "message": f"VÆ°á»£t quÃ¡ giá»›i háº¡n request: {e.description}",
        "retry_after": getattr(e, 'retry_after', None)
    }), 429

@app.errorhandler(500)
def internal_error(error):
    logger.error(f"Internal server error: {error}")
    return jsonify({
        "success": False,
        "error": "INTERNAL_SERVER_ERROR",
        "message": "Lá»—i server ná»™i bá»™"
    }), 500

# =============================================================================
# SIGNAL HANDLERS
# =============================================================================

def signal_handler(sig, frame):
    """Xá»­ lÃ½ tÃ­n hiá»‡u Ä‘á»ƒ shutdown gracefully"""
    logger.info(f"Nháº­n signal {sig}, Ä‘ang shutdown server...")
    
    # Cáº­p nháº­t tráº¡ng thÃ¡i náº¿u Ä‘ang cháº¡y
    if processing_state.get_state()["is_running"]:
        processing_state.update(
            message="Server Ä‘ang shutdown...",
            error="Server bá»‹ shutdown"
        )
    
    # Cleanup
    logger.info("Cleaning up...")
    sys.exit(0)

# ÄÄƒng kÃ½ signal handlers
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# =============================================================================
# STARTUP AND MAIN
# =============================================================================

def print_startup_banner():
    """In banner khá»Ÿi Ä‘á»™ng"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  ğŸš€ ANOMALY DETECTION API v2.0               â•‘
â•‘                     Enhanced & Production Ready               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“¡ API Endpoints:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Health & Status:                                            â”‚
â”‚    GET  /api/health          - Health check with details     â”‚
â”‚    GET  /api/status          - Processing status             â”‚
â”‚    GET  /api/system-info     - System information            â”‚
â”‚                                                              â”‚
â”‚  Processing Control:                                         â”‚
â”‚    POST /api/start           - Start anomaly detection       â”‚
â”‚    POST /api/stop            - Stop processing               â”‚
â”‚                                                              â”‚
â”‚  Data & Results:                                             â”‚
â”‚    GET  /api/results         - Get detection results         â”‚
â”‚    GET  /api/download/<type> - Download files                â”‚
â”‚    GET  /api/history         - Processing history            â”‚
â”‚                                                              â”‚
â”‚  Configuration:                                              â”‚
â”‚    GET  /api/config          - Get configuration             â”‚
â”‚    POST /api/config          - Update configuration          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸŒ Server Details:
   URL: http://localhost:5000
   Environment: {'Development' if app.debug else 'Production'}
   
ğŸ“š Features:
   âœ… Rate limiting protection
   âœ… Enhanced error handling  
   âœ… Thread-safe state management
   âœ… Request validation
   âœ… Comprehensive logging
   âœ… Graceful shutdown
   âœ… System resource monitoring
   âœ… Configuration backup
   âœ… Pagination support

ğŸ“‹ Logs: api_server.log
ğŸ”§ Debug: {'Enabled' if app.debug else 'Disabled'}
    """
    print(banner)
    print("=" * 66)

def initialize_app():
    """Khá»Ÿi táº¡o á»©ng dá»¥ng"""
    try:
        # Táº¡o thÆ° má»¥c cáº§n thiáº¿t
        ensure_directories()
        
        # Kiá»ƒm tra dependencies
        required_modules = ['pandas', 'flask', 'flask_cors']
        missing_modules = []
        
        for module in required_modules:
            try:
                __import__(module)
            except ImportError:
                missing_modules.append(module)
        
        if missing_modules:
            logger.error(f"Thiáº¿u cÃ¡c module: {missing_modules}")
            return False
        
        # Khá»Ÿi táº¡o config
        try:
            config = AnomalyDetectionConfig()
            logger.info("âœ… Configuration loaded successfully")
        except Exception as e:
            logger.error(f"âŒ Cannot load configuration: {e}")
            return False
        
        # Kiá»ƒm tra tÃ i nguyÃªn há»‡ thá»‘ng
        if not _check_system_resources():
            logger.warning("âš ï¸  System resources may be insufficient")
        else:
            logger.info("âœ… System resources check passed")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Failed to initialize app: {e}")
        return False

if __name__ == '__main__':
    print_startup_banner()
    
    # Khá»Ÿi táº¡o á»©ng dá»¥ng
    if not initialize_app():
        logger.error("âŒ Application initialization failed")
        sys.exit(1)
    
    # Cáº¥u hÃ¬nh server
    host = os.getenv('API_HOST', '0.0.0.0')
    port = int(os.getenv('API_PORT', 5000))
    debug = os.getenv('API_DEBUG', 'True').lower() in ['true', '1', 'yes']
    
    logger.info(f"ğŸš€ Starting server on {host}:{port}")
    logger.info(f"ğŸ”§ Debug mode: {debug}")
    
    try:
        app.run(
            debug=debug,
            host=host,
            port=port,
            threaded=True,
            use_reloader=debug  # Chá»‰ reload trong debug mode
        )
    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ Server stopped by user")
    except Exception as e:
        logger.error(f"âŒ Server error: {e}")
        sys.exit(1)